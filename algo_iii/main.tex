\input{../document.setup}
\usemintedstyle{borland}

\input{custom.commands.tex}
\title{Algoritmos III - Apuntes para final}
\author{Gianfranco Zamboni}

\usepackage[backend=biber,style=chem-acs,sorting=none]{biblatex}
\nocite{*}

\addbibresource{bibliography.bib}

\usemintedstyle[cpp]{bordeland, tabsize=2}
\input{../page.setup}
\setcounter{tocdepth}{3}
	\begin{document}
	\input{tikz.configuration}
	
	\maketitle
	\tableofcontents

\newpage
\section{Introducción}
Un \textbf{algoritmo} es una secuencia \textbf{finita} de pasos  \textbf{precisos} (no deben requerir tomar ninguna decisión subjetiva, ni hacer uso de la intuición o la creatividad) necesarias para llevar a cabo un cálculo de manera correcta.

Se dice que un algoritmo está \textbf{bien definido} cuando toda ejecución del mismo bajo los mismos parámetros devuelve el mismo resultado. Hay que tener en cuenta que si bien esto es lo deseable en la mayoría de los casos, muchas veces es necesario usar variables aleatorias o heurísiticas para conseguir un resultado medianamente decente para problemas que no tienen solución o que son muy dificiles de calcular de manera exacta.

\subsection{Analisis de algoritmos}

\paragraph{Análisis empírico:} Implementarlo en una máquina determinada utilizando un lenguaje determinado, correrlo para un conjunto de instancias y comparar sus tiempos de ejecución. Esto implicaría perder tiempo y esfuerzo programandolo, ejecutandolo y además probarlo con un conjunto de instancias acotados por lo que realmente no se podría concluir nada sobre su comportomiento con instancias que queden fuera de ese conjunto.

\paragraph{Análisis teórico:} Determinar matemáticamente la cantidad de tiempo que llevará su ejecución como una función de la medidad de la instancia considerada, independinzándolo de la máquina sobre la cuál es implementado el algoritmo y el lenguaje para hacerlo. Para esto es necesario definir un modelo de cómputo, un lenguaje sobre este modelo, cuales son las instancias del problema relevantes al mismo y sus tamaños.

Dicho de otra forma, desde el punto de vista teórico, se busca determinar la velocidad de crecimiento del tiempo o el espacio requerido por el algoritmo en función del tamaño de las instancias del problema.

Dado un problema, se le asigna un entero \(n\) (llamado el \textbf{tamaño} del problema) que servirá como medida de la cantidad de datos de entrada. Y se define como \textbf{complejidad temporal} del algoritmo al tiempo ejecución de un algoritmo expresado como una función que depende de \(n\).

Análogamente, se puede definir la \textbf{complejidad espacial} del algoritmo como el espacio de memoria necesario para su ejecución en función del tamaño del problema.

\paragraph{Complejidad peor caso:} Se toma como complejidad del algoritmo la función que dada una instancia de tamaño de $n$, devuelve la máxima complejidad posible sobre todas las instancias de ese tamaño.

\paragraph{Complejidad caso promedio:} Se toma como complejidad del algoritmo la función que dada una instancia de tamaño de $n$, devuelve el promedio de todas las complejidades posible sobre todas las instancias de ese tamaño.

\subsubsection{Modelo Random Access Machine (RAM)}
Una Random Access Machine (RAM) modela una computadora con un único registro acumulador en la cuál las instrucciones no pueden modificarse. La misma está formada por:

\begin{itemize}
	\item Una \textbf{unidad de entrada} que contiene los datos necesarios para poder ejecutar una corrida del algoritmo. La misma es de solo lectura y, en cada una de sus celdas, puede contener un entero de tamaño arbitrario. Cuando un valor es leído, la cinta se avanza una celda.
	\item Una \textbf{unidad de salida} que es de solo escritrura y se encuentra inicialmente vacía. Cuando una instrucción es ejecutada, se imprime un entero en la celda que se encuentra bajo la lectora y luego se la avanza una posición.
	\item Una \textbf{memoria} que consiste en una secuencia infinita de registros, cada uno de los cuales puede contener un entero de tamaño arbitrario. 
	\item Un \textbf{programa} es una secuencia de instrucciones etiquetadas que no está almacenado en memoria. Asumimos que las instrucciones que contiene un programa, son las instrucciones aritméticas básicas, de entradas/salidas y direccionamiento indirecto y de branching encontradas en la mayoría de las computadoras.
\end{itemize}

Este modelo se usa cuando los tamaños de los problemas a resolver es lo suficientemente pequeño como para que entren en la memoría principal de una computadora o cuando los enteros usados en la computación son los suficientemente chicos como para que entren en una palabra de la misma.

\subsection{Cálculo de complejidad}
\subsubsection{Tamaño de una instancia}
Para especificar la complejidad en peor caso (tanto espacial como temporal), debemos especificar el tiempo de ejecución requerido por cada instrucción y el espacio de cada registro.

La forma más simple para esto es usar el \textbf{criterio de costo uniforme} en el que cada instrucción requiere una unidad de tiempo y cada registro requiere una unidad de espacio. En general, usaremos este criterio para analizar problemas de ordenamientos o sobre grafos y matrices.


Una segunda opción (un poco más realista), es tomar en cuenta el tamaño real (en bits) de los operandos. Este el \textbf{criterio de costo logarítmico} que toma en cuenta que son necesarios para representar los datos. 
\paragraph{Alfabeto:} Es el conjunto de símbolos que puede interpretar en una máquina. Por ejemplo, las computadoras actuales reconocen el alfabeto binario \(\{0,1\}\).

\vspace*{5mm}
Dada una instancia \(I\), se define \(|I|\) como el número de símbolos de un alfabeto finito necesarios para codificar \(I\). Este tamaño depende del alfabeto elegido.  En el caso de las computadoras actuales, que se manejan con el alfabeto binario, para almacenar un número natural \(n\), se necesitan \(L(n) = \lfloor\log_2{n}\rfloor + 1\) bits.

Usaremos este criterio cuando analicemos problemas sobre números (por ejemplo, el calculo de un factorial).

\subsubsection{Funciones de complejidad}
Dadas dos funciones \(f,g:\nat\to\reales\) decimos que:
\begin{itemize}
	\item \(f(n) = O(g(n))\) si existen \(c\in\reales_+ y n_0\in\nat\) tales que
	\[f(n)\leq cg(n) \text{ para todo } n\geq n_0\]
	\item \(f(n) = \Omega(g(n))\) si existen \(c\in\reales_+ y n_0\in\nat\) tales que
	\[f(n)\geq cg(n) \text{ para todo } n\geq n_0\]
	\item \(f(n) = \Theta(g(n))\) si \[f(n) = O(g(n)) \text{ y } f(n)= \Omega(g(n))\]
\end{itemize}

\subsubsection{Problemas bien resueltos}
Decimos que un problema está \textbf{bien resuelto} si existe un algoritmo de complejidad polinomial que lo resuelva. Es decir, que no consideraremos soluciones sastifactorios a los algoritmos supra-polinomiales.

\subsection{Técnicas de diseño de algoritmos}
\subsubsection{Algoritmos golosos}
Los algoritmos golosos toman decisiones basandose en la información disponible actualemente, sin considerar los efectos que esas decisiones podrían tener en el fúturo. Son fáciles de inventar, implementar y son eficientes. Sin embargo, aunque muchas veces proporcionan heurísticas sencillas para resolver problemas de optimización, no siempre funcionan.

Comunmente, los algoritmos golosos y los problemas que pueden resolver tienen las siguientes carácteristicas:
\begin{itemize}
	\item El problema se debe resolver de alguna manera óptima. Para construir su solución se mantiene \textbf{un conjunto de candidatos} entre los cuales el algoritmo puede elegir para agregar a la solución en el próximo paso. Por ejemplo, un conjunto de monedas o de nodos de un grafos.
	\item A medida que el algoritmo progresa, se acumulan dos conjuntos: Uno contiene candidatos que ya fueron considerados y usados; el otro contiene los candadidatos que fueron consiradosy rechazados.
	\item Hay una \textbf{función de verificación} que dado un conjunto de candidatos verifica si puede ser una solución valida al problema propuesto auque esta no sea la solución óptima.
	\item Hay una \textbf{función de factibilidad} que dado un conjunto de candidatos verifica si se puede extender con nuevos candidatos para conseguir una solución al problema.
	\item Hay una \textbf{función de selección} que decide cual de los candidatos disponibles (que no fueron elegidos ni rechazados) es el más prometedor para hacercanos a la solución deseada.
	\item Hay una f\textbf{función objetivo} que nos da el valor de la solución encontrada. Por ejemplo, el número de monedas utilizadas para el cambio, o la cantidad de nodos usados en un cámino, o cualquier otro valor que estemos intentando optimizar. A diferencia de las otras tres funciones mencionadas anteriormente, esta no aparece explicitamente en el algoritmo goloso.
\end{itemize}

Estructura general de un algoritmo goloso:

\begin{algorithmic}
	\Function{greedy}{\(C\): Set}
	\Comment{\(C\) es el conjunto de candidatos}
	\State \(S\gets\emptyset\)
	\Comment{Conjunto en el que se construye la solución}
	\While{ \(C\neq\emptyset~\land~\lnot\Call{esSolucion}{S}\)}
		\State \(x \gets \Call{seleccionar}{C}\)
		\State \(C \gets C~\backslash~\{x\}\)
		\If{\(\Call{esValido}{S\cup\{x\}}\)}
			\State \(S\gets S\cup\{x\}\)
		\EndIf
	\EndWhile
	\If{\(\Call{esSolucion}{S}\)}
		\Return \(S\)
	\Else
		\State\Return Error: No hay solución
	\EndIf
	\EndFunction
\end{algorithmic}

\subsubsection{Divide and Conquer}
Es una técnica que consiste en dividir la instancia de un problema a resolver en varias instancias más pequeñas del mismo problema y resolverlas de manera independiente para luego combinar sus soluciones en la solución de la instancia original. 

Para que valga la pena realizar un algoritmo con esta técnica se deben cumplir tres condiciones:

\begin{enumerate}
	\item Debe ser posible descomponer las instancias en subinstancias y combinar las subsoluciones de manera eficiente.
	\item Las subinstancias deben ser todas más o menos del mismo tamaño. La mayoría de los algoritmos de divide and conquer son tales que el tamaño de una subinstancia \(I\), es aproximadamente \(\frac{n}{b}\) donde \(n\) es el tamaño de la instancia original y \(b\) alguna constante.
\end{enumerate}

La estructura general de un álgortimo de divide and conquer es la siguiente:

\begin{algorithmic}
	\Function{DivideAndConquer}{\(I\): Instancia del problema}
	\If{\(I\) es suficientemente pequeño o simple}
		\Return \(\texttt{resolver}(I)\)
	\Else
		\State Descomponer \(I\) en subinstancias \(I_1, I_2,\dots, I_k\)
		\For{\(i\gets 1~\textbf{to}~k\)}
			\State \(y_i \gets \Call{DivideAndConquer}{I_i}\)
		\EndFor
		\State Combinar las soluciones \(y_1, y_2,\dots, y_k\) obtenidas para obtener la solución \(y\) de \(I\)
		\State\Return \(y\)
	\EndIf

	\EndFunction
\end{algorithmic}

\subsubsection{Backtracking}
Es una técnica que permite recorrer sistemáticamente todas las posibles configuraciones del espacio de soluciones de un problema computacional. Cuando el algoritmo comienza, no se sabe nada sobre la solución del problema. A medida que va avanzando, se agrega un elemento a la solución para ir consiguiendo soluciones parciales. Si en algún momento, la solución parcial deja de poder ser extendida entonces esa solución se descarta.

Se puede pensar este espacio como un árbol dirigido, donde cada vértice representa una solución parcial \(s\) y un vértice \(x\) es hijo de \(s\) si la solución parcial \(x\) se puede extender desde \(s\). 

El template general para algoritmos de este tipo es: 

\begin{algorithmic}
	\State \texttt{sol}: Vector \(\gets [] \)
	\State \texttt{encontro}: Booleano \(\gets false \)
	\Function{backtracking}{\(v[1\dots k], s\): Instancia del problema}
	\If{\(k == 0~\land~esSolucion(s)\) }
	\State\(\texttt{sol} \gets s\)
	\State \(\texttt{encontro} \gets true\)
	\Else
		\For{\(i \gets 1 \textbf{ to } k\)}
%			\State \Call{backtracking}{\(v[1\dots k]\backslash \{v_i\},~s\cup\{v_i\} \)}
			\If{encontro}~\Return
			\EndIf
		\EndFor
	\EndIf
	\EndFunction
\end{algorithmic}

\subsubsection{Programación dinámica}

Es una técnica que consiste en tomar la subinstancia más pequeña del problema, resolverla e ir extendiendo la solución para instancias cada vez mas grandes. Esta técnica es un método \textbf{bottom-up}, es decir tomamos las instancias más simples del problema y la vamos extendiendo y combinando hasta conseguir la solución correspondiente a la instancia original.

La programación dinámica se utiliza para resolver problemas de optimización que cumplen con el \textbf{principio de optimalidad de bellman} que nos asegura que si tomamos una serie de decisiones óptimas, entonces todas las subsecuencias de decisiones de esa serie son óptimas.

\subsubsection{Algoritmos probabilísticos}
Cuando un algoritmo tiene que hacer una elección, a veces es preferible elegir al azar en vez e gastar mucho tiempo tratando de ver cual es la mejor opción.

Una de las características de los algoritmos probabilisticos es que puede comportarse de maneras distintas si se lo usa para computar una misma instancia dos o más veces. Su tiempo de ejecución y resultados pueden variar considerablemente de un uso a otro pudiendo incluso nunca llegar a terminar en ciertas corridas para una instancia específica. Sin embargo, dada la posibilidad de reiniciar el algoritmo y obtener un resultado válido éste es un comportamiento que no molesta. 

Por otro lado, una consecuencia de este comportamiento es que, si hay más de una solución al problema, las mismas se pueden obtener corriendo el algoritmo más de una vez.s

Los algoritmos probabílisticos se pueden clasificar dependiendo de la probabilidad de que devuelvan una respuesta correcta:

\begin{itemize}
	\item \textbf{Algoritmos númericos}: Estos algoritmos devuelven un intervalo de confianza (del estilo ``La solución es \( x \pm y\) con probabilidad \(z\))". Por lo general, mientras más tiempo de proceso les demos, mas preciso es el intervalo que devuelven.
	\item \textbf{Algoritmos de Montecarlo}: Son algoritmo que dan la respuesta exacta con alta probabilidad. Por lo general, no es posible verificar que la respuesta dada sea correcta sin embargo la probabilidad de error disminuye mientras más tiempo se este ejecutando el algoritmo.
	\item \textbf{Algoritmos Las Vegas:} Son algoritmos que siempre dan una respuesta correcta pero puede llegar a no dar ninguna respuesta. 
	\item \textbf{Algoritmos Sherwood:} Son algoritmos que agregan una componente aleatoria a algoritmos determinísticos para tratar de evitar tiempos de ejecución del peor caso. Un ejemplo de esto es el Quicksort con pivote seleccionado aleatoriamente.
\end{itemize}

\subsubsection{Heurísticas}
Dado un problema de optimización \(\sqcap\) díficl de resolver (y para el cual probablemente no exista un algoritmo eficiente), los \textbf{algoritmos heurísticos} definen un procedimiento que intenta conseguir soluciones para el mismo pero puede devolver resultados erróneos o no devolver nada directamente.

En otras palabras: Sea \(I\) es una instancaia del problema y \(x^*(I)\) el valor óptimo de la función a optmizar en dicha instancia. Buscamos crear una heurística \(H\) tal que la solución \(x^H(I)\) devuelta por la misma sea lo más cercano a \(x^*(I)\) posible.

\paragraph{Algoritmos apróximados:} Decimos que \(H\) es un algoritmo \(\epsilon-\)aproximado para el problema \(\sqcap\) si para algún \(\epsilon > 0\) vale que \(|x^H(I) - x^*(I)\leq\epsilon|x^*(I)|\)

\paragraph{Algoritmos con certificados:} Por lo general, si bien los problemas dificiles no pueden ser resueltos con algoritmos polinomiales si se puede verificar que las soluciones provistas por las heurísticas sean correctas con algoritmos polinomiales. 

Se dice que los algoritmos diseñados para realizar esta verificación proveen un certificado que afirma la validez de la soluciones propuestas por una heurística.

\printbibliography[keyword=intro,title={Bibliografía}]

\newpage
\section{Grafos}
\subsection{Definiciones básicas}
\subsubsection{Tipos de grafo}
Un grafo \(G = (V,X)\) es un par de conjuntos, donde \(V\) es un conjunto de \textbf{puntos / nodos / vértices} y \(X\) es un subconjunot del conjunto de pares no ordenados de elementos distintos de \(V\). Los elementos de \(X\) se llamas \textbf{aristas, ejes o arcos}.

\begin{figure}
\begin{center}

	\begin{tikzpicture}
	\node[basicNode] (p) {\(p\)};
	\node[basicNode] (q) [right=of p] {\(q\)};
	\node[basicNode] (r) [below=of p] {\(r\)};
	\node[basicNode] (s) [below=of q] {\(s\)};
	
	\path
	(p) edge (q)
	(p) edge (r)
	(p) edge (s)
	(q) edge (s)
	(r) edge (s)
	;		
	\end{tikzpicture}
\end{center}
	\caption{\(G =([p,~q,~r,~s],~[(p,q),~(p,s),~(q,s),~(r,s)])\)
	}
\end{figure}

Dados \(v\) y \(w \in V\), si \(e=(v,w)\in X\) se dice que \(v\) y \(w\) son \textbf{adyacentes} y que \(e\) es \textbf{incidente} a \(v\) y a \(w\).

\paragraph{Multigrafo:} Es un grafo en el que puede haber varias aristas entre el mismo par de nodos distintos.
		\begin{figure}[H]
	\begin{center}
		\begin{tikzpicture}
		\node[basicNode] (p) {\(p\)};
		\node[basicNode] (q) [right=of p] {\(q\)};
		\path
		(p) edge[out=10, in=170] (q)
		(p) edge[out=-10, in=-170] (q)
		;		
		\end{tikzpicture}
	\end{center}		
	\caption{Multigrafo}
\end{figure}
\paragraph{Seudografo:} Es un grafo en el que puede haber varias aristas entre cada par de nodos y también puede haber aristas (\textit{loops}) que unan a un nodo con sí mismo.
	
\begin{figure}[H]
	\begin{center}
		\begin{tikzpicture}
		\node[basicNode] (p) {\(p\)};
		\path
		(p) edge[loop left] (p);		
		\end{tikzpicture}
	\end{center}		
	\caption{Multigrafo}
\end{figure}

\paragraph{N}
\subsubsection{Propiedades de un nodo}
\appendix
\section{Hoja de complejidades}
\begin{center}
\begin{tabular}{|l|c|}
	\hline
	\textbf{Algoritmo} & \textbf{Complejidad} \\
	\hline
	\multicolumn{2}{|c|}{\cellcolor{blue!25}\textbf{De Búsqueda}}\\
	\hline
	Secuencial & \(O(n)\) \\
	\hline
	Binaria & \(O(\log{n})\) \\
	\hline
	\multicolumn{2}{|c|}{\cellcolor{blue!25}\textbf{De Ordenamiento}}\\
	\hline
	Bubblesort & \(O(n^2)\) \\
	\hline
	Quicksort & \(O(n^2)\) \\
	\hline
	Heapsort & \(O(n\log{n})\)* \\
	\hline
\end{tabular}
\end{center}

\paragraph{*} \(O(n\log{n})\) es la complejidad óptima para algoritmos de ordenamiento basados en comparaciones. 

\color{red}

Grafos Definiciones básicas: adyacencia, grado de un nodo, isomorfismos, caminos, conexión, etc. Grafos bipartitos. Arboles: caracterización, árboles orientados, árbol generador. Enumeración. Grafos eulerianos y hamiltonianos. Planaridad. Coloreo. Número cromático. Matching, conjunto independiente, recubrimiento. Recubrimiento de aristas y vértices.



Algoritmos en grafos y aplicaciones Representación de un grafo en la computadora: matrices de incidencia y adyacencia, listas. Algoritmos de búsqueda en grafos: BFS, DFS, A*. Mínimo árbol generador, algoritmos de Prim y Kruskal. Arboles ordenados: códigos unívocamente descifrables. Algoritmos para detección de circuitos. Algoritmos para encontrar el camino mínimo en un grafo: Dijkstra, Ford, Dantzig. Planificación de procesos: PERT/CPM. Algoritmos heurísticos: ejemplos. Nociones de evaluación de heurísticas y de técnicas metaheurísticas. Algoritmos aproximados. Heurísticas para el problema del viajante de comercio. Algoritmos para detectar planaridad. Algoritmos para coloreo de grafos. Algoritmos para encontrar el flujo máximo en una red: Ford y Fulkerson. Matching: algoritmos para correspondencias máximas en grafos bipartitos. Otras aplicaciones.



Problemas NP-completos Problemas tratables e intratables. Problemas de decisión. P y NP. Maquinas de Turing no determinísticas. Problemas NP-completos. Relación entre P y NP. Problemas de grafos NP-completos: coloreo de grafos, grafos hamiltonianos, recubrimiento mínimo de las aristas, corte máximo, etc.
\end{document}

