\section{Introducción}
\subsection{Relaciones}
Dados dos conjuntos \(A\) y \(B\), se llama \textbf{relación} \(R: A \to B\) de \(A\) en \(B\) a todo subconjutno de \(A\times B\), es decir \(R\subset A\times B\).

Dos elementos \(a\in A\) y \(b\in B\) están relacionados si \((a,b)\in R\) y lo notamos \(aRb\).

Si \(A = B\), se dice que \(R\) es una relación sobre \(A\) y se dice que:
\begin{itemize}
  \item es \textbf{reflexica} cuando \(\forall a,~aRa\).
  \item es \textbf{simétrica} cuando \(\forall a,b\in A,~aRb \implies bRa\).
  \item es \textbf{transitiva} cuando \(a,b,c\in A,~aRb~\land~bRc\implies aRc\).
\end{itemize}

\paragraph{Relación de equivalencia:} Una relación \(R:A\to A\) es de \textbf{equivalencia} cuando es reflexiva, simétrica y transitiva. Este tipo de relaciones particiona a \(A\) en subconjuntos disjuntos llamados \textbf{clases de equivalencia}.


\subsubsection{Operaciones}
\paragraph{Composición de relaciones:} Si \(R:A\to B\) y \(S:B\to C\) son relaciones, entonces la composición de \(R\) y \(S\) es la relación \(S\circ R:A\to C\) definida por:
\[S\circ R = \{(a,c)~|~a\in A,~c\in C : \exists b\in B,~aRb~\land~bSc\}\]

\paragraph{Relación de identidad:} La relación de identidad sobre \(A\) es la relación \(id_A:A\to A\) definida por: \(id_A = \{(a,a)~|~a\in A\}\).
\begin{itemize}
  \item La relación de identidad el el elemento neutro de la composición de relaciones.
\end{itemize}

\paragraph{Relación de potencia:} Dado \(R: A\to A\) se define la relación de potencia \(R^k: A\to A\) como la composición de \(k\) copias de \(R\):
\[R^n = \left\{
  \begin{array}{ll}
    id_A           & \text{si } n = 0 \\
    R\circ R^{n-1} & \text{si } n > 0
  \end{array}
  \right.
\]

\paragraph{Clausura transitiva/positiva:} Dada una relación \(R:A\to A\) se define la clausura transitiva de \(R\) como la relación \(R^+\) definida por: \[R^+ = \bigcup_{n=1}^\infty R^n\]

La clausura transitiva de \(R\) cumple las siguientes propiedades:
\begin{enumerate}
  \item \(R\subseteq R^+\)
        \newpage
  \item \(R^+\) es transitiva
        \begin{demo}[0.86\textwidth]
          ~Si \(a R^+ b\) entonces existe una secuencia de elementos \(a = \red{a_0, a_1, \dots, a_n} = b\) tales que \(\red{a_i} R \red{a_{i+1}}\) para todo \(i\in [0,n-1]\).

          \vspace*{0.25cm}
          Análogamente, como \(b R^+ c\) existe una secuencia de elementos \(b = \blue{b_0, b_1, \dots, b_m} = c\) tales que \(\blue{b_i} R \blue{b_{i+1}}\) para todo \(i\in [0,m-1]\).

          \vspace*{0.25cm}
          Entonces \(a R^{n+m} c\) pues puedo armar la secuencia \(a = \red{a_0, a_1, \dots, a_n},\blue{b_1\dots b_m} = c\).

          \vspace*{0.25cm}
          Luego como \(R^{n+m}\subseteq R^+\) vale que \(a R^+ c\).
        \end{demo}

  \item Para toda relación \(G:A\to A\) tal que \(R\subseteq G \land G\) es transitiva, entonces \(R^+\subseteq G\), es decir \(R^+\) es la relación transitiva más pequeña que contiene a \(R\).
        \begin{demo}[0.86\textwidth]
          Si \(a R^+ b\) entonces existe una secuencia de elementos \(a = a_0, a_1, \dots, a_n = b\) tales que \(a_i R a_{i+1}\) para todo \(i\in [0,n-1]\).

          \vspace*{0.25cm}
          Como \(R\subseteq G\) entonces \(a_i G a_{i+1}\) para todo \(i\in [0,n-1]\). Como \(G\) es transitiva entonces la aplicación repetida de la transitividad nos lleva a que \(a_1 G a_n\), por lo que \(a G b\).
        \end{demo}
\end{enumerate}

\paragraph{Clausura transitiva reflexiva:} \[ R^* = R^+ \cup id_A = \bigcup_{n=0}^\infty R^n\]

\paragraph{Observaciones:}
\begin{itemize}
  \item Si \(A\) es un conjunto finito, entonces todas las relaciones \(R:A\to A\) son finitas.
  \item Si \(R\) es reflexiva, entonces \(R^* = R^+\).
\end{itemize}



\subsection{Alfabetos}
\paragraph{Alfabeto:} Un alfabeto es un conjunto finito de símbolos.

\paragraph{Cadena:} Una cadena sobre un alfabeto \(\Sigma\) es una secuencia finita de símbolos de \(\Sigma\). Los símbolos son notados respetando el orden de la secuencia.

\paragraph{Concatenación:} Es una operación entre un símbolo del alfabeto \(\Sigma\) y una cadena sobre dicho alfabeto:
\[ \circ : \Sigma\times\{\text{cadenas sobre }\Sigma\}\to\{\text{cadenas de }\Sigma\}\]
\begin{itemize}
  \item La cadena nula \(\lambda\) es el elemento neutro de la concatenación.
\end{itemize}

\paragraph{Clausura de Kleene de \(\Sigma\): \(\Sigma^*\)}
\begin{itemize}
  \item \(\lambda\in\Sigma^*\)
  \item \(\alpha\in\Sigma^*\implies \forall~a\in\Sigma,~a\circ\alpha\in\Sigma^*\)
\end{itemize}

\paragraph{Clausura positiva de \(\Sigma\):} \(\Sigma^+ = \Sigma^*\setminus\{\lambda\}\)

\subsection{Lenguajes}
\paragraph{Lenguaje:} Un lenguaje es un conjunto de cadenas sobre un alfabeto \(\Sigma\).

\paragraph{Concatenación de lenguajes:} Si \(L_1\) y \(L_2\) son lenguajes definidos sobre los alfabetos \(\Sigma_1\) y \(\Sigma_2\) respectivamente, entonces la concatenación de \(L_1\) y \(L_2\) es un lenguaje \(L_1L_2\) sobre el alfabeto \( \Sigma_1\cup\Sigma_2\) dfinido de la siguiente manera:
\[ L_1L_2 = \{ \alpha\beta~|~\alpha\in L_1,~\beta\in L_2\}\]

\paragraph*{Clausura de Kleene \(L^*\):}
\begin{itemize}
  \item[] \(L^0 = \{\lambda\}\)
  \item[] \(L^n = LL^{n-1}\) para \(n>=1\)
  \item[] \(L^* = \overset{\infty}{\underset{n=0}{\bigcup}} L^n\)
\end{itemize}

\paragraph{Clausura positiva \(L^+\):}
\begin{itemize}
  \item[] \(L^+ = \overset{\infty}{\underset{n=1}{\bigcup}} L^n\)
\end{itemize}
\paragraph*{Observaciones:}
\begin{itemize}
  \item \(L^+ = LL^*\)
  \item \(L^* = L^+\cup\{\lambda\}\)
  \item Si \(L\) es un lenguaje definido sobre \(\Sigma\) entonces \(L\subseteq\Sigma^*\)
\end{itemize}

\subsection{Gramáticas}
Una gramática es una 4-tupla \((V_N,V_T,P,S)\) donde:
\begin{itemize}
  \item \(V_N\) es un conjunto finito de símbolos no terminales.
  \item \(V_T\) es un conjunto finito de símbolos terminales.
  \item \(P\) es un conjunto finito de reglas de producción: Son pares ordenados \(\alpha\to \beta\) donde \[\alpha\in(V_N\cup V_T)^*V_N(V_N\cup V_T)^*\text{ y }\beta\in(V_N\cup V_T)^*\]
  \item \(S\in V_N\) es el símbolo inicial.
\end{itemize}

Dada una producción \(A\to\alpha\in P\), se denomina a \(A\) como \textbf{cabeza} de la producción y a \(\alpha\) como su \textbf{cuerpo}.

\paragraph{Derivación:} El el proceso por el cual se obtiene una cadena a partir de un símbolo inicial remplazando recursivamente símbolos no terminales por cuerpos de producciones en \(P\) cuya cabeza coincida con los símbolos que están siendo remplazados.

\paragraph{Forma setencial de una grámatica:} Se llama forma sentencial a cualquier derivación de la grámatica:
\begin{itemize}
  \item \(S\) es una forma setencial de \(G\)
  \item Si \(\alpha\beta\gamma\) es una forma setencial de \(G\) y \(\beta\to\delta\in P\) entonces \(\alpha\delta\gamma\) es una forma setencial de \(G\).
\end{itemize}

\paragraph{Derivación directa en \(G\):} Si \(\alpha\beta\gamma\in(V_N\cup V_T)^*\) y \(\beta\to\delta\in P\) entonces \(\alpha\delta\gamma\) es una derivación directa de \(G\) de \(\alpha\beta\gamma\) y se denota como \(\alpha\beta\gamma\underset{G}{\implies}\alpha\delta\gamma\).
\begin{itemize}
  \item \(\overset{+}{\underset{G}{\implies}}\) es la clausura positiva.
  \item \(\overset{*}{\underset{G}{\implies}}\) es la clausura transitiva y reflexiva.
  \item \(\overset{k}{\underset{G}{\implies}}\) será la potencia \(k\)-ésima.
\end{itemize}

\paragraph{Lenguaje de una grámatica \(\mathcal{L}(G)\):} Es el conjunto de todas las cadenas de símbolos terminales que son formas setenciales de \(G\).

\[ \mathcal{L}(G) = \{ \alpha\in V_T^*:~S\overset{+}{\underset{G}{\implies}}\alpha\}\]

\subsubsection{Clasificación de grámaticas (Chomsky)}
\paragraph{Gramáticas regulares (tipo 3):} Son aquellas gramáticas que cumplen alguna de las siguientes condiciones:
\begin{itemize}
  \item Todas sus producciones son de la forma \(A\to aB\) ó \(A\to a\) ó \(A\to\lambda\) donde \(A,B\in V_N\) y \(a\in V_T\). En este caso se dice que es una gramática lineal a derecha.
  \item Todas sus producciones son de la forma \(A\to Ba\) ó \(A\to a\) ó \(A\to\lambda\) donde \(A,B\in V_N\) y \(a\in V_T\). En este caso se dice que es una gramática lineal a izquierda.
\end{itemize}

\paragraph{Gramáticas libres de contexto (tipo 2):} Son aquellas gramáticas en las que cada producción es de la forma \(A\to\alpha\) donde \(A\in V_N\) y \(\alpha\in(V_N\cup V_T)^*\).

De la definición anterior puede inferirse que toda grámatica regular es libre de contexto.

\paragraph{Gramáticas sensibles al contexto (tipo 1):} Son aquellas gramáticas en las que cada producción es de la forma \(\alpha\to\beta\) donde \(\alpha,\beta\in(V_N\cup V_T)^*\) y \(|\alpha|\leq |\beta|\).
Se puede inferir que toda gramática independiente del contexto que no posea regla borradoraas (es decir, que no posea producciones de la forma \(A\to\lambda\)) es sensible al contexto.

\paragraph{Gramáticas sin restricciones (tipo 0):} Son aquellas gramáticas que no poseen ninguna restricción sobre la forma de sus producciones. El conjunto de las grámaticas tipo 0 es el conjunto de todas las grámaticas y permite generar todos los lenguajes aceptados por una máquina de Turing.

\paragraph{Definición:} Un lenguaje generado por una grámatica tipo \(t\) es llamado \textbf{lenguaje tipo \(t\)}.